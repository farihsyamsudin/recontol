#!/bin/bash

# Pastikan semua tools yang dibutuhkan terinstal
function check_dependencies {
    local tools=("assetfinder" "dnsx" "httpx" "hakrawler" "waybackurls" "gauplus" "unfurl" "gf" "nuclei" "naabu" "gowitness")
    echo "[*] Memeriksa dependensi..."
    for tool in "${tools[@]}"; do
        if ! command -v "$tool" &> /dev/null; then
            echo "[!] Error: '$tool' tidak ditemukan. Mohon instal terlebih dahulu."
            exit 1
        fi
    done
    echo "[*] Semua dependensi terpenuhi."
}

# Fungsi untuk membuat laporan ringkasan
function create_summary_report {
    echo "[*] Membuat laporan ringkasan..."
    
    local report_file="$outdir/summary_report.txt"
    echo "--- Laporan Reconnaisance untuk $domain ---" > "$report_file"
    echo "Dibuat pada: $(date)" >> "$report_file"
    echo "--------------------------------------------------------" >> "$report_file"
    echo "" >> "$report_file"

    echo "--- Ringkasan Utama ---" >> "$report_file"
    echo "Total Subdomain Ditemukan: $(wc -l < "$outdir/recon/subdomains_raw.txt")" >> "$report_file"
    echo "Total Subdomain Aktif: $(wc -l < "$outdir/recon/subdomains_alive.txt")" >> "$report_file"
    echo "Total URL Dikumpulkan: $(wc -l < "$outdir/recon/all_urls.txt")" >> "$report_file"
    echo "Total Parameter Unik: $(wc -l < "$outdir/recon/params.txt")" >> "$report_file"
    echo "" >> "$report_file"

    echo "--- Temuan Potensial (dari GF) ---" >> "$report_file"
    for pattern in xss sqli ssrf lfi rce idor redirect; do
        if [ -s "$outdir/scans/gf_$pattern.txt" ]; then
            echo "- URL Rentan $pattern: $(wc -l < "$outdir/scans/gf_$pattern.txt")" >> "$report_file"
        fi
    done
    echo "" >> "$report_file"

    echo "--- Hasil Scan Nuclei (Kerentanan Tinggi & Kritis) ---" >> "$report_file"
    # Gunakan jq untuk memfilter dan menampilkan hasil yang paling penting
    if [ -s "$outdir/scans/nuclei_results.json" ]; then
        cat "$outdir/scans/nuclei_results.json" | jq -r 'select(.info.severity | IN("critical", "high")) | "- [\u001b[31m" + (.info.severity | ascii_upcase) + "\u001b[0m] " + .host + " - " + .info.name' >> "$report_file"
    else
        echo "Tidak ada temuan dengan tingkat keparahan Tinggi atau Kritis." >> "$report_file"
    fi
    echo "" >> "$report_file"

    echo "--- Temuan Port Terbuka (dari Naabu) ---" >> "$report_file"
    if [ -s "$outdir/scans/naabu_ports.txt" ]; then
        cat "$outdir/scans/naabu_ports.txt" >> "$report_file"
    else
        echo "Tidak ada port terbuka yang ditemukan." >> "$report_file"
    fi
    echo "" >> "$report_file"

    echo "[*] Laporan lengkap tersimpan di: $report_file"
}

# Cek argumen dan dependensi
check_dependencies

if [ -z "$1" ]; then
    echo "Usage: recontol <domain.com>"
    exit 1
fi

domain=$1
timestamp=$(date +"%Y%m%d-%H%M%S")
outdir="recontol-${domain}-${timestamp}"

echo "[*] Recon dimulai untuk $domain"
echo "[*] Direktori output: $outdir"

# Buat direktori yang dibutuhkan
mkdir -p "$outdir/recon"
mkdir -p "$outdir/scans"
mkdir -p "$outdir/visuals"

# 1. Subdomain enumeration
echo "[*] Menjalankan assetfinder..."
assetfinder --subs-only $domain | tee "$outdir/recon/subdomains_raw.txt"

# 2. Validasi subdomain aktif (dnsx)
echo "[*] Memvalidasi subdomain aktif dengan dnsx..."
cat "$outdir/recon/subdomains_raw.txt" | dnsx -silent > "$outdir/recon/subdomains_alive.txt"

# 3. Port scanning dengan Naabu
echo "[*] Memindai port terbuka dengan Naabu..."
cat "$outdir/recon/subdomains_alive.txt" | naabu -silent > "$outdir/scans/naabu_ports.txt"

# 4. Ambil HTTP info dengan httpx (format JSON untuk analisis)
echo "[*] Mendapatkan informasi HTTP dengan httpx..."
cat "$outdir/recon/subdomains_alive.txt" | httpx -title -status-code -tech-detect -json -silent > "$outdir/recon/httpx_output.json"

# 5. Screenshot dengan Gowitness
echo "[*] Mengambil tangkapan layar dengan Gowitness..."
gowitness file -f "$outdir/recon/subdomains_alive.txt" -o "$outdir/visuals/" >/dev/null

# 6. Crawl dengan Hakrawler, Wayback, dan Gauplus (jalankan paralel)
echo "[*] Mengumpulkan URL dari Hakrawler, Wayback, dan Gauplus..."
cat "$outdir/recon/subdomains_alive.txt" | hakrawler -depth 2 -plain > "$outdir/recon/hakrawler_urls.txt" &
cat "$outdir/recon/subdomains_alive.txt" | waybackurls > "$outdir/recon/waybackurls.txt" &
cat "$outdir/recon/subdomains_alive.txt" | gauplus > "$outdir/recon/gauplus_urls.txt" &
wait # Tunggu semua proses selesai

# Gabungkan semua URL unik
cat "$outdir/recon/hakrawler_urls.txt" "$outdir/recon/waybackurls.txt" "$outdir/recon/gauplus_urls.txt" | sort -u > "$outdir/recon/all_urls.txt"

# 7. Ekstrak parameter dengan unfurl
echo "[*] Mengekstrak parameter dengan unfurl..."
cat "$outdir/recon/all_urls.txt" | unfurl --unique keys > "$outdir/recon/params.txt"

# 8. GF pattern matching (xss, sqli, ssrf, dll)
echo "[*] Menjalankan GF pattern matching..."
for pattern in xss sqli ssrf lfi rce idor redirect; do
    cat "$outdir/recon/all_urls.txt" | gf $pattern > "$outdir/scans/gf_$pattern.txt"
done

# 9. Jalankan Nuclei pada subdomain aktif (format JSON)
echo "[*] Menjalankan scan Nuclei..."
cat "$outdir/recon/subdomains_alive.txt" | nuclei -silent -severity low,medium,high,critical -json > "$outdir/scans/nuclei_results.json"

# 10. Ekstrak IPs dan map dengan mapcidr
echo "[*] Mengekstrak IP dan memetakan CIDR..."
cat "$outdir/recon/subdomains_alive.txt" | httpx -ip -silent | cut -d " " -f2 | sort -u > "$outdir/recon/ips.txt"
cat "$outdir/recon/ips.txt" | mapcidr -silent > "$outdir/recon/cidr_mapped.txt"

echo ""
echo "[*] Proses recon selesai untuk $domain!"
create_summary_report